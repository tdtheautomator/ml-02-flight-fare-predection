{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Dataset has 11 features.\n",
    "\n",
    "1. **Airline**: The name of the airline company is stored in the airline column. It is a categorical feature having 6 different airlines.\n",
    "2. **Flight**: Flight stores information regarding the plane's flight code. It is a categorical feature.\n",
    "3. **Source City**: City from which the flight takes off. It is a categorical feature having 6 unique cities.\n",
    "4. **Departure Time**: This is a derived categorical feature obtained created by grouping time periods into bins. It stores information about the departure time and have 6 unique time labels.\n",
    "5. **Stops**: A categorical feature with 3 distinct values that stores the number of stops between the source and destination cities.\n",
    "6. **Arrival Time**: This is a derived categorical feature created by grouping time intervals into bins. It has six distinct time labels and keeps information about the arrival time.\n",
    "7. **Destination City**: City where the flight will land. It is a categorical feature having 6 unique cities.\n",
    "8. **Class**: A categorical feature that contains information on seat class; it has two distinct values: Business and Economy.\n",
    "9. **Duration**: A continuous feature that displays the overall amount of time it takes to travel between cities in hours.\n",
    "10. **Days Left**: This is a derived characteristic that is calculated by subtracting the trip date by the booking date.\n",
    "11. **Price**: Target variable stores information of the ticket price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed for exploratory data analysis (eda) and feature engineering (fe)\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import libraries needed for model training\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor, ExtraTreesRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None) #display all possible columns\n",
    "for dirname, _, filenames in os.walk('../data'): \n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename)) #list all files in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/clean_dataset.csv') #load data into dataframe\n",
    "df.head(5) #display head (top 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5) #display tail (last 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape: \",df.shape) #get total shape of dataset, total rows and columns\n",
    "print(\"Number of Columns:\", df.shape[1])\n",
    "print(\"Number of Rows:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #quick info about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose() #statistics for numerical datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1, inplace = True) #drop unwanted column permanently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() #number of missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna() #drop rows with any NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Duplicates: \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates() #drop rows with duplicate vales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() #number of unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #show all cloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "print('Numerical Features : {} : {}'.format(len(numerical_features), numerical_features))\n",
    "print('Categorical Features : {} : {}'.format(len(categorical_features), categorical_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique values in categorical columns\n",
    "for column in categorical_features:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in column '{column}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #quick info about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose() #statistics for numerical datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['price'],axis=1) #dataframe contains all cloumns which shold be used to predicted\n",
    "y=df['price'] #series contains to be predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.head())\n",
    "print(type(x)) #datatype of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.head())\n",
    "print(type(y)) #datatype of y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding & Feature Scaling\n",
    "\n",
    "**Encoding** is transform **categorical data** into numerical representations which can be understood by machine learning algotihhms.\n",
    "Common types of Encoding :\n",
    "1. One-Hot Encoding (OHE)\n",
    "   Good for categories with no inherent prder or relationship. Each category is represented as a binary vector. This is most widely used technique.\n",
    "2. Label Encoding\n",
    "   Suitable for dataset with two distinct categories (eg size of t-shirt), each categories are assigned integer values.\n",
    "3. Ordinal Encoding\n",
    "   Similar to label encoding however the explicit mapping can be provided for integer assignments. (eg education degree)\n",
    "\n",
    "Scaling is used to improve the consistency of numerical features. StandardScaler is the most common type of scaling applied to numerical features.\n",
    "\n",
    "Standardization is a data preparation method that involves adjusting the input (features) by first centering them (subtracting the mean from each data point) and then dividing them by the standard deviation, resulting in the data having a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "**StandardScaler** is used to standardize the input data in a way that ensures that the data points have a balanced scale, which is crucial for machine learning algorithms, especially those that are sensitive to differences in feature scales.\n",
    "\n",
    "\n",
    "**ColumnTransformer** allows different features of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space.\n",
    "Example we will apply onehot encoding to categorical features and standard scaler to numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numerical_features = x.select_dtypes(exclude=\"object\").columns\n",
    "categorical_features = x.select_dtypes(include=\"object\").columns\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "ohe_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", ohe_transformer, categorical_features),\n",
    "         (\"StandardScaler\", numerical_transformer, numerical_features),\n",
    "    ]\n",
    ")\n",
    "X = preprocessor.fit_transform(x)   #pre-processing source data x data and saving in X \n",
    "print(f\"Shape of original data (x): {x.shape}\")\n",
    "print(f\"Shape of transformed data (X): {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training & Test Data\n",
    "\n",
    "- Data needs to be split into training and test.Refer https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- x is original dataset of independent features\n",
    "- X is encoded dataset of independent features\n",
    "- y is dependent data which needs to be predicted\n",
    "- Training dataset is applied with fit_transform()\n",
    "- Test dataset is applied with transform()\n",
    "- The fit() method is calculating the mean and variance of each of the features present in our data. \n",
    "- The transform() method is transforming all the features using the respective mean and variance.\n",
    "- The fit_transform() method is used on the training data so that we can scale the training data and also learn the scaling parameters of that data.\n",
    "- To avoid any bias the test data is nto applied with fit and only transform.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=None) #using 20% to test and 80% for training.\n",
    "print(f\"Shape of training data : {X_train.shape}\")\n",
    "print(f\"Shape of test data : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Performance Metrics\n",
    "\n",
    "### MAE (Mean Absolute Error)\n",
    "The MAE value itself indicates the average absolute error between predicted and actual values. The smaller the MAE, the better the model’s predictions align with the actual data.\n",
    "\n",
    "### MSE (Mean Squared Error)\n",
    "Mean squared error (MSE) measures the amount of error in statistical models. It assesses the average squared difference between the observed and predicted values. When a model has no error, the MSE equals zero. As model error increases, its value increases. The mean squared error is also known as the mean squared deviation (MSD).\n",
    "\n",
    "### RMSE (Root Mean Square Error)\n",
    "The root mean square error (RMSE) measures the average difference between a statistical model’s predicted values and the actual values. Mathematically, it is the standard deviation of the residuals. Residuals represent the distance between the regression line and the data points.Use the root mean square error to assess the amount of error in a regression or other statistical model. A value of 0 means that the predicted values perfectly match the actual values, but you’ll never see that in practice. Low RMSE values indicate that the model fits the data well and has more precise predictions. \n",
    "\n",
    "\n",
    "### R-Squared (R²)\n",
    "R-Squared (R²) is a statistical measure used to determine the proportion of variance in a dependent variable that can be predicted or explained by an independent variable.\n",
    "In other words, R-Squared shows how well a regression model (independent variable) predicts the outcome of observed data (dependent variable).\n",
    "R-Squared is also commonly known as the coefficient of determination. It is a goodness of fit model for linear regression analysis.Higher R-squared values suggest a better fit, but it doesn’t necessarily mean the model is a good predictor in an absolute sense.\n",
    "\n",
    "### Adjusted R-Squared (R²)\n",
    "Adjusted R-squared addresses a limitation of Adjusted R Squared, especially in multiple regression (models with more than one independent variable). Adjusted R-squared vs adjusted r squared penalizes the addition of unnecessary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise dataframe for Regression Performace Metrics\n",
    "performance_metrics={\n",
    "    'Model Name':[], \n",
    "    'MAE':[] ,\n",
    "#    'MSE':[] ,\n",
    "    'RMSE':[] ,\n",
    "    'R2 Score':[],\n",
    "    'Adjusted R2 Score':[] ,\n",
    "    'Training Duration':[],\n",
    "    'Predection Duration':[],\n",
    "    'Evaluation Duration':[]\n",
    "    }\n",
    "df_ModelPerformance=pd.DataFrame(performance_metrics)\n",
    "print(type(df_ModelPerformance))\n",
    "df_ModelPerformance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "#Define a function to evaluate model\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = root_mean_squared_error(true, predicted)\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Models\n",
    "\n",
    "models = {\n",
    "    \"Linear\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Bagging\": BaggingRegressor(),\n",
    "    \"ExtraTrees\": ExtraTreesRegressor(),\n",
    "    #\"SVR\": SVR(),\n",
    "    #\"K-Neighbors\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"Gradient Boost\": GradientBoostingRegressor(),\n",
    "    \"CatBoosting\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost\": AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "for key, value in models.items():\n",
    "    model_name = key\n",
    "    model = value\n",
    "    test_performance_metrics = {}\n",
    "\n",
    "    print('-'*80)\n",
    "    \n",
    "    t1=time.time()\n",
    "    print(f'{datetime.datetime.fromtimestamp(t1).strftime(\"%Y-%m-%d %H:%M:%S\")} - {model_name} - performing training')\n",
    "    model.fit(X_train, y_train) # Training the Model with training dataset\n",
    "\n",
    "    # Predicting Values of test dataset\n",
    "    \n",
    "    t2=time.time()\n",
    "    #print(f'{datetime.datetime.fromtimestamp(t2).strftime(\"%Y-%m-%d %H:%M:%S\")} - {model_name} - predecting training dataset')\n",
    "    #y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    t3=time.time()\n",
    "    print(f'{datetime.datetime.fromtimestamp(t3).strftime(\"%Y-%m-%d %H:%M:%S\")} - {model_name} - predecting test dataset')\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluating Model Performance\n",
    "    \n",
    "    t4=time.time()\n",
    "    #print(f'{datetime.datetime.fromtimestamp(t4).strftime(\"%Y-%m-%d %H:%M:%S\")} - {model_name} - evaluating performance of training dataset')\n",
    "    #model_train_mae ,model_train_mse, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "    \n",
    "    \n",
    "    t5=time.time()\n",
    "    print(f'{datetime.datetime.fromtimestamp(t5).strftime(\"%Y-%m-%d %H:%M:%S\")} - {model_name} - evaluating performance of test dataset')\n",
    "    model_test_mae ,model_test_mse, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)    \n",
    "    \n",
    "    t6=time.time()\n",
    "    #model_train_adjusted_r2 = (1 - (1-model_train_r2)*(len(y)-1)/(len(y)-x.shape[1]-1))\n",
    "    #model_train_mae = round(model_train_mae,2)\n",
    "    ##model_train_mse = round(model_train_mse,2)\n",
    "    #model_train_rmse = round(model_train_rmse,2)\n",
    "    #model_train_r2 = round(model_train_r2,2)\n",
    "    #model_train_adjusted_r2 = round(model_train_adjusted_r2,2)\n",
    "    #model_train_duration = round(float(t2-t1),2)\n",
    "    #model_train_pred_duration = round(float(t3-t2),2)\n",
    "    #model_train_eval_duration = round(float(t5-t4),2)\n",
    "\n",
    "    model_test_adjusted_r2 = (1 - (1-model_test_r2)*(len(y)-1)/(len(y)-x.shape[1]-1))\n",
    "    model_test_mae = round(model_test_mae,2)\n",
    "    #model_test_mse = round(model_test_mse,2)\n",
    "    model_test_rmse = round(model_test_rmse,2)\n",
    "    model_test_r2 = round(model_test_r2,2)\n",
    "    model_test_adjusted_r2 = round(model_test_adjusted_r2,2)\n",
    "    model_test_duration = round(float(0),2)\n",
    "    model_test_pred_duration = round(float(t4-t3),2)\n",
    "    model_test_eval_duration = round(float(t6-t5),2)\n",
    "    \n",
    "    \n",
    "    #train_performance_metrics=pd.DataFrame({'Model Name':f'{model_name} (Train)', \n",
    "    #                                    'MAE':[model_train_mae] ,\n",
    "    #                                    #'MSE':[model_train_mse] ,\n",
    "    #                                    'RMSE':[model_train_rmse] ,\n",
    "    #                                    'R2 Score':[model_train_r2],\n",
    "    #                                    'Adjusted R2 Score':[model_train_adjusted_r2],\n",
    "    #                                    'Training Duration':[model_train_duration],\n",
    "    #                                    'Predection Duration':[model_train_pred_duration],\n",
    "    #                                    'Evaluation Duration':[model_train_eval_duration]\n",
    "    #                                    })\n",
    "\n",
    "    test_performance_metrics=pd.DataFrame({'Model Name':f'{model_name} (Test)', \n",
    "                                        'MAE':[model_test_mae] ,\n",
    "                                        #'MSE':[model_test_mse] ,\n",
    "                                        'RMSE':[model_test_rmse] ,\n",
    "                                        'R2 Score':[model_test_r2],\n",
    "                                        'Adjusted R2 Score':[model_test_adjusted_r2],\n",
    "                                         'Training Duration':[model_test_duration],\n",
    "                                        'Predection Duration':[model_test_pred_duration],\n",
    "                                        'Evaluation Duration':[model_test_eval_duration]\n",
    "                                        })\n",
    "\n",
    "    #df_ModelPerformance = pd.concat([train_performance_metrics,df_ModelPerformance], ignore_index=True)\n",
    "    df_ModelPerformance = pd.concat([test_performance_metrics,df_ModelPerformance], ignore_index=True)\n",
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "filepath = f'../outputs/{time.strftime(\"%Y%m%d_%H%M%S\")}_ModelPerformance.csv'\n",
    "df_ModelPerformance.to_csv(filepath)  \n",
    "df_ModelPerformance\n",
    "\n",
    "#df_ModelPerformance.drop(df_ModelPerformance.tail(1).index,inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
